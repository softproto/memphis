services:

  backend:
    build:
      context: .
      target: builder
    depends_on:
      db:
        condition: service_healthy
    env_file: .env

  db:
    image: postgres:alpine
    restart: always
    # user: postgres
    # secrets:
    #   - db-password
    volumes:
      - db-data:/var/lib/postgresql/data
    environment:
      - POSTGRES_USER=postgres
      - POSTGRES_PASSWORD=postgres
      - POSTGRES_DB=db
      # - POSTGRES_PASSWORD_FILE=/run/secrets/db-password
    ports:
      - 5433:5432
    # expose:
    #   - 5432
    healthcheck:
      test: [ "CMD", "pg_isready" ]
      interval: 10s
      timeout: 5s
      retries: 5

  redis:
    image: "redis:alpine"
    restart: always
    ports:
      - 6380:6380
    command: redis-server --port 6380

  influxdb:
    image: influxdb:2.7.10
    restart: always
    environment:
      DOCKER_INFLUXDB_INIT_MODE: setup
      DOCKER_INFLUXDB_INIT_ORG: business
      DOCKER_INFLUXDB_INIT_BUCKET: users_business_events
      DOCKER_INFLUXDB_INIT_USERNAME: ${INFLUXDB_USERNAME}
      DOCKER_INFLUXDB_INIT_PASSWORD: ${INFLUXDB_PASSWORD}
    ports:
      - "8086:8086"
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  grafana:
    image: grafana/grafana:latest
    ports:
      - "3000:3000"
    depends_on:
      - influxdb
    restart: always
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  zookeeper:
    image: bitnami/zookeeper:latest
    restart: on-failure
    ports:
      - "2181:2181"
    environment:
      ZOO_MY_ID: 1
      ZOO_PORT: 2181
      ZOO_SERVERS: server.1=zookeeper:2888:3888
      ALLOW_ANONYMOUS_LOGIN: "yes"

  kafka:
    image: bitnami/kafka:latest
    restart: on-failure
    ports:
      - "9092:9092"
    environment:
      KAFKA_ADVERTISED_LISTENERS: INTERNAL://kafka:29092,EXTERNAL://localhost:9092
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: INTERNAL:PLAINTEXT,EXTERNAL:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: INTERNAL
      KAFKA_ZOOKEEPER_CONNECT: "zookeeper:2181"
      KAFKA_BROKER_ID: 1
      KAFKA_LOG4J_LOGGERS: "kafka.controller=INFO,kafka.producer.async.DefaultEventHandler=INFO,state.change.logger=INFO"
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_CFG_ZOOKEEPER_CONNECT: zookeeper:2181
      ALLOW_PLAINTEXT_LISTENER: "yes"
      KAFKA_LISTENERS: "INTERNAL://:29092,EXTERNAL://:9092"
      KAFKA_ZOOKEEPER_SESSION_TIMEOUT: "6000"
      KAFKA_RESTART_ATTEMPTS: "10"
      KAFKA_RESTART_DELAY: "5"
      ZOOKEEPER_AUTOPURGE_PURGE_INTERVAL: "0"
    healthcheck:
      test: kafka-topics.sh --list --bootstrap-server localhost:9092 || exit 1
      interval: 1s
      timeout: 60s
      retries: 60
    depends_on:
      - zookeeper

  kowl:
    image: quay.io/cloudhut/kowl:v1.4.0
    restart: on-failure
    volumes:
      - ./kowl_config:/etc/kowl/
    ports:
      - "8080:8080"
    entrypoint: ./kowl --config.filepath=/etc/kowl/config.yaml
    depends_on:
      - kafka

  proxy:
    image: nginx
    volumes:
      - type: bind
        source: ./proxy/nginx.conf
        target: /etc/nginx/conf.d/default.conf
        read_only: true
    ports:
      - 80:80
    depends_on:
      - backend

volumes:
  db-data:


